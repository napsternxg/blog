
<!DOCTYPE html>
<html lang="en">
<head>
  <link href='//fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,700,400italic' rel='stylesheet' type='text/css'>

    <link rel="stylesheet" type="text/css" href="http://shubhanshu.com/blog/theme/stylesheet/style.min.css">

  <link rel="stylesheet" type="text/css" href="http://shubhanshu.com/blog/theme/pygments/friendly.min.css">
  <link rel="stylesheet" type="text/css" href="http://shubhanshu.com/blog/theme/font-awesome/css/font-awesome.min.css">


    <link href="http://shubhanshu.com/blog/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="Interpreting Models Atom">



  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="HandheldFriendly" content="True" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="robots" content="" />


<meta name="author" content="Shubhanshu Mishra" />
<meta name="description" content="Semi-supervised way of learning graph embeddings" />
<meta name="keywords" content="deeplearning">

<meta property="og:site_name" content="Interpreting Models"/>
<meta property="og:title" content="Revisiting Semi-Supervised Learning with Graph Embeddings"/>
<meta property="og:description" content="Semi-supervised way of learning graph embeddings"/>
<meta property="og:locale" content="en_US"/>
<meta property="og:url" content="http://shubhanshu.com/blog/blog/semi-sup-graphemb-salakh.html"/>
<meta property="og:type" content="article"/>
<meta property="article:published_time" content="2016-04-04 10:20:00-05:00"/>
<meta property="article:modified_time" content="2016-04-04 10:20:00-05:00"/>
<meta property="article:author" content="http://shubhanshu.com/blog/author/shubhanshu-mishra.html">
<meta property="article:section" content="reviews"/>
<meta property="article:tag" content="deeplearning"/>
<meta property="og:image" content="/assets/images/pic.jpg">

  <title>Interpreting Models &ndash; Revisiting Semi-Supervised Learning with Graph Embeddings</title>

</head>
<body>
  <aside>
    <div>
      <a href="http://shubhanshu.com/blog">
        <img src="/assets/images/pic.jpg" alt="Interpreting Models" title="Interpreting Models">
      </a>
      <h1><a href="http://shubhanshu.com/blog">Interpreting Models</a></h1>

<p>A quest to make models interpretable</p>
      <nav>
        <ul class="list">

          <li><a href="http://shubhanshu.com/" target="_blank">Homepage</a></li>
          <li><a href="http://shubhanshu.com/playground.html" target="_blank">Projects</a></li>
          <li><a href="https://github.com/napsternxg/blog" target="_blank">Blog Repo</a></li>
        </ul>
      </nav>

      <ul class="social">
        <li><a class="sc-website" href="http://shubhanshu.com" target="_blank"><i class="fa fa-website"></i></a></li>
        <li><a class="sc-twitter" href="http://twitter.com/TheShubhanshu" target="_blank"><i class="fa fa-twitter"></i></a></li>
        <li><a class="sc-linkedin" href="http://www.linkedin.com/in/shubhanshumishra" target="_blank"><i class="fa fa-linkedin"></i></a></li>
        <li><a class="sc-github" href="http://github.com/napsternxg" target="_blank"><i class="fa fa-github"></i></a></li>
        <li><a class="sc-rss" href="//shubhanshu.com/blog/feeds/all.atom.xml" target="_blank"><i class="fa fa-rss"></i></a></li>
      </ul>
    </div>


  </aside>
  <main>

    <nav>
      <a href="http://shubhanshu.com/blog">    Home
</a>

      <a href="/blog/blog/archives/archives.html">Archives</a>
      <a href="/blog/blog/category/">Categories</a>
      <a href="/blog/blog/tag/">Tags</a>

      <a href="http://shubhanshu.com/blog/feeds/all.atom.xml">    Atom
</a>

    </nav>

<article class="single">
  <header>
      
    <h1 id="semi-sup-graphemb-salakh">Revisiting Semi-Supervised Learning with Graph Embeddings</h1>
    <p>
          Posted on Mon 04 April 2016 in <a href="http://shubhanshu.com/blog/blog/category/reviews.html">reviews</a>


    </p>
  </header>


  <div>
    <p><strong>Authors: Zhilin Yang, William Cohen, Ruslan Salakhutdinov</strong></p>
<h2>Overview</h2>
<p>This is an interesting paper which describes a semi-supervised learning algorithm for Graph Embedding. The authors have build up on the DeepWalk [1] and LINE [2] algorithms which learn embeddings of nodes in a graph in a similar way Word2Vec Skipgram model [3] learns word embeddings based on context. They add a semi-supervised component using both Transductive and Inductive learning, which utilizes partially labeled data to jointly train the model to predict the class of the labeled nodes and the context of the all nodes. The authors report an increase in accuracy over other semi-supervised methods, on several text classification, entity extraction and entity classification tasks.</p>
<h2>Thoughts</h2>
<p>I found the paper to be really interesting because of its ability to lay some foundation in joint training of embeddings on labeled and unlabled data. The authors differentiate their paper from other semi-supervised algorithms in its use of graph to identify context of the instances, while at the same time using features of each instance.</p>
<p>It is interesting to see, how many algorithms have build up on the word2vec skipgram approach to learn embeddings for the data instances. One of the major challenges with the approach is coming up with a proper way to generate the negative samples. Papers like DeepWalk and LINE use a random walk approach to generate the negative samples from the data. The authors have presented a really useful way to sample the positive and negative samples from the graph which, at the same time ensures that the labeled data is also present in each sample while training.</p>
<p>The authors' presentation of the transductive and inductive variants of the algorithms, presents a framework to apply this approach to cases where the predictions need to be done on in-sample unlabeled data (transductive) as well as out of sample unlabeled data (inductive).</p>
<p>One issue I found with the paper was the <em>Experiments</em> sections and the data used for the analysis. The CiteSeer, CORA and PubMed data are relatively small in my understanding, to describe the efficiency of this model. However, on the larger DIEL data, the algorithms' significant performance improvement can be taken as a measure of its strength over other mentioned algorithms.</p>
<p>Overall, I think it is a very useful paper which will push the Machine Learning field forward by further utilizing the vector embedding approach and nicely incorporating it into a semi-supervised setting.</p>
<p>It would be interesting to use the same approach on Skip-Thought vectors [4] or paragraph vectors connected by topics, users etc.</p>
<h2>References</h2>
<p>[1] Perozzi, Bryan, Rami Al-Rfou, and Steven Skiena. "Deepwalk: Online learning of social representations." Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 2014.</p>
<p>[2] Tang, Jian, et al. "Line: Large-scale information network embedding." Proceedings of the 24th International Conference on World Wide Web. International World Wide Web Conferences Steering Committee, 2015.</p>
<p>[3] Mikolov, Tomas, et al. "Distributed representations of words and phrases and their compositionality." Advances in neural information processing systems. 2013.</p>
<p>[4] Kiros, Ryan, et al. "Skip-thought vectors." Advances in Neural Information Processing Systems. 2015.</p>
<div class="highlight"><pre><span></span>@misc{1603.08861,
Author = {Zhilin Yang and William Cohen and Ruslan Salakhutdinov},
Title = {Revisiting Semi-Supervised Learning with Graph Embeddings},
Year = {2016},
Eprint = {arXiv:1603.08861},
}
</pre></div>
  </div>
  <div class="tag-cloud">
    <p>
      <a href="http://shubhanshu.com/blog/blog/tag/deeplearning.html">deeplearning</a>
    </p>
  </div>



    <div class="addthis_relatedposts_inline">


<!-- Disqus -->
<div id="disqus_thread"></div>
<script type="text/javascript">
    var disqus_shortname = 'shubhanshu-blog';
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript>
        Please enable JavaScript to view comments.

</noscript>
<!-- End Disqus -->
</article>

    <footer>
<p>
  &copy;  2016 - This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>
</p>
<p>    Powered by <a href="http://getpelican.com" target="_blank">Pelican</a> - <a href="https://github.com/alexandrevicenzi/flex" target="_blank">Flex</a> theme by <a href="http://alexandrevicenzi.com" target="_blank">Alexandre Vicenzi</a>
</p><p>
  <a rel="license"
     href="http://creativecommons.org/licenses/by-sa/4.0/"
     target="_blank">
    <img alt="Creative Commons License"
         title="Creative Commons License"
         style="border-width:0"
         src="https://i.creativecommons.org/l/by-sa/4.0/80x15.png"
         width="80"
         height="15"/>
  </a>
</p>    </footer>
  </main>

<!-- Google Analytics -->
<script type="text/javascript">
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-44393164-1', 'auto');
  ga('send', 'pageview');
</script>
<!-- End Google Analytics -->



<script type="application/ld+json">
{
  "@context" : "http://schema.org",
  "@type" : "Blog",
  "name": " Interpreting Models ",
  "url" : "http://shubhanshu.com/blog",
  "image": "/assets/images/pic.jpg",
  "description": "Shubhanshu Mishra's thoughts on mathematical models and code"
}
</script>

</body>
</html>